{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-Project 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base code to generate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# On some implementations of matplotlib, you may need to change this value\n",
    "IMAGE_SIZE = 72\n",
    "\n",
    "def generate_a_drawing(figsize, U, V, noise=0.0):\n",
    "    fig = plt.figure(figsize=(figsize,figsize))\n",
    "    ax = plt.subplot(111)\n",
    "    plt.axis('Off')\n",
    "    ax.set_xlim(0,figsize)\n",
    "    ax.set_ylim(0,figsize)\n",
    "    ax.fill(U, V, \"k\")\n",
    "    fig.canvas.draw()\n",
    "    imdata = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)[::3].astype(np.float32)\n",
    "    imdata = imdata + noise * np.random.random(imdata.size)\n",
    "    plt.close(fig)\n",
    "    return imdata\n",
    "\n",
    "def generate_a_rectangle(noise=0.0, free_location=False):\n",
    "    figsize = 1.0    \n",
    "    U = np.zeros(4)\n",
    "    V = np.zeros(4)\n",
    "    if free_location:\n",
    "        corners = np.random.random(4)\n",
    "        top = max(corners[0], corners[1])\n",
    "        bottom = min(corners[0], corners[1])\n",
    "        left = min(corners[2], corners[3])\n",
    "        right = max(corners[2], corners[3])\n",
    "    else:\n",
    "        side = (0.3 + 0.7 * np.random.random()) * figsize\n",
    "        top = figsize/2 + side/2\n",
    "        bottom = figsize/2 - side/2\n",
    "        left = bottom\n",
    "        right = top\n",
    "    U[0] = U[1] = top\n",
    "    U[2] = U[3] = bottom\n",
    "    V[0] = V[3] = left\n",
    "    V[1] = V[2] = right\n",
    "    return generate_a_drawing(figsize, U, V, noise)\n",
    "\n",
    "\n",
    "def generate_a_disk(noise=0.0, free_location=False):\n",
    "    figsize = 1.0\n",
    "    if free_location:\n",
    "        center = np.random.random(2)\n",
    "    else:\n",
    "        center = (figsize/2, figsize/2)\n",
    "    radius = (0.3 + 0.7 * np.random.random()) * figsize/2\n",
    "    N = 50\n",
    "    U = np.zeros(N)\n",
    "    V = np.zeros(N)\n",
    "    i = 0\n",
    "    for t in np.linspace(0, 2*np.pi, N):\n",
    "        U[i] = center[0] + np.cos(t) * radius\n",
    "        V[i] = center[1] + np.sin(t) * radius\n",
    "        i = i + 1\n",
    "    return generate_a_drawing(figsize, U, V, noise)\n",
    "\n",
    "def generate_a_triangle(noise=0.0, free_location=False):\n",
    "    figsize = 1.0\n",
    "    if free_location:\n",
    "        U = np.random.random(3)\n",
    "        V = np.random.random(3)\n",
    "    else:\n",
    "        size = (0.3 + 0.7 * np.random.random())*figsize/2\n",
    "        middle = figsize/2\n",
    "        U = (middle, middle+size, middle-size)\n",
    "        V = (middle+size, middle-size, middle-size)\n",
    "    imdata = generate_a_drawing(figsize, U, V, noise)\n",
    "    return [imdata, [U[0], V[0], U[1], V[1], U[2], V[2]]]\n",
    "\n",
    "\n",
    "im = generate_a_rectangle(10, True)\n",
    "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
    "\n",
    "im = generate_a_disk(10)\n",
    "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
    "\n",
    "[im, v] = generate_a_triangle(20, False)\n",
    "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
    "\n",
    "\n",
    "def generate_dataset_classification(nb_samples, noise=0.0, free_location=False):\n",
    "    # Getting im_size:\n",
    "    im_size = generate_a_rectangle().shape[0]\n",
    "    X = np.zeros([nb_samples,im_size])\n",
    "    Y = np.zeros(nb_samples)\n",
    "    print('Creating data:')\n",
    "    for i in range(nb_samples):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        category = np.random.randint(3)\n",
    "        if category == 0:\n",
    "            X[i] = generate_a_rectangle(noise, free_location)\n",
    "        elif category == 1: \n",
    "            X[i] = generate_a_disk(noise, free_location)\n",
    "        else:\n",
    "            [X[i], V] = generate_a_triangle(noise, free_location)\n",
    "        Y[i] = category\n",
    "    X = (X + noise) / (255 + 2 * noise)\n",
    "    return [X, Y]\n",
    "\n",
    "def generate_test_set_classification():\n",
    "    np.random.seed(42)\n",
    "    [X_test, Y_test] = generate_dataset_classification(300, 20, True)\n",
    "    Y_test = to_categorical(Y_test, 3) \n",
    "    return [X_test, Y_test]\n",
    "\n",
    "def generate_dataset_regression(nb_samples, noise=0.0):\n",
    "    # Getting im_size:\n",
    "    im_size = generate_a_triangle()[0].shape[0]\n",
    "    X = np.zeros([nb_samples,im_size])\n",
    "    Y = np.zeros([nb_samples, 6])\n",
    "    print('Creating data:')\n",
    "    for i in range(nb_samples):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        [X[i], Y[i]] = generate_a_triangle(noise, True)\n",
    "    X = (X + noise) / (255 + 2 * noise)\n",
    "    return [X, Y]\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def visualize_prediction(x, y):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    I = x.reshape((IMAGE_SIZE,IMAGE_SIZE))\n",
    "    ax.imshow(I, extent=[-0.15,1.15,-0.15,1.15],cmap='gray')\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "\n",
    "    xy = y.reshape(3,2)\n",
    "    tri = patches.Polygon(xy, closed=True, fill = False, edgecolor = 'r', linewidth = 5, alpha = 0.5)\n",
    "    ax.add_patch(tri)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def generate_test_set_regression():\n",
    "    np.random.seed(42)\n",
    "    [X_test, Y_test] = generate_dataset_regression(300, 20)\n",
    "    return [X_test, Y_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Simple Classification\n",
    "\n",
    "First, we generate a training set of 300 images of three geometric shapes (rectangle, disk, triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, Y_train] = generate_dataset_classification(300, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can build 2 linear classifiers : Stochastic Gradient Descent (SGD) and Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten,Convolution2D, MaxPooling2D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_Y=encoder.transform(Y_train)\n",
    "\n",
    "def create_baseline_adam():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim=5184))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "def create_baseline_SGD():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim=5184))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_baseline_SGD()\n",
    "labels = to_categorical(Y_train, num_classes=3)\n",
    "model.fit(X_train, labels,epochs=50, batch_size=32)\n",
    "\n",
    "\n",
    "X_test= generate_a_disk()\n",
    "X_test = X_test.reshape(1, X_test.shape[0])\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_baseline_adam()\n",
    "labels = to_categorical(Y_train, num_classes=3)\n",
    "model.fit(X_train, labels,epochs=50, batch_size=32)\n",
    "\n",
    "\n",
    "X_test= generate_a_disk()\n",
    "X_test = X_test.reshape(1, X_test.shape[0])\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we observe that the Adam optimizer has a higher lever of complexity (computing time) but the loss is very low in comparison with SGD optimizer.\n",
    "We can conclude after several tests that the two classifiers seems to be relevant, because they predict successfully the right shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Visualization of the Solution\n",
    "\n",
    "We keep the Adam optimizer and we want to visualize the weights of this classifier as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column1=model.get_weights()[0][:,0]\n",
    "column2=model.get_weights()[0][:,1]\n",
    "column3=model.get_weights()[0][:,2]\n",
    "\n",
    "IMAGE_SIZE = 72\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(column1.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(column2.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(column3.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the three columns and we note that it is very hard to distinguish the three shapes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 A More Difficult Classification problem\n",
    "\n",
    "We train our Adam classifier on a training set of 300 images with geometric shapes (which have now a free location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, Y_train] = generate_dataset_classification(300, 20, True)\n",
    "\n",
    "model=create_baseline_adam()\n",
    "labels = to_categorical(Y_train, num_classes=3)\n",
    "model.fit(X_train, labels,epochs=50, batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test it on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_test, Y_test] = generate_test_set_classification()\n",
    "model.evaluate(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the loss is 0.86 and the accuracy is 0.56.\n",
    "\n",
    "The result is disappointing and we can conclude that this classifier is not adequate anymore. \n",
    "\n",
    "In order to improve these results, we can build a convolutional network.\n",
    "There are 1 convolutional layer with 16 5x5 filters, 1 pooling layer and one fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_conv():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(16, (5, 5), activation='relu', input_shape=(72,72,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model=create_baseline_conv()\n",
    "labels = to_categorical(Y_train, num_classes=3)\n",
    "\n",
    "test = X_train.reshape(X_train.shape[0], 72, 72 , 1)\n",
    "\n",
    "model.fit(test, labels,epochs=50, batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computional time is higher than previous classifiers because the model is more complex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_test, Y_test] = generate_test_set_classification()\n",
    "test2=X_test.reshape(X_test.shape[0], 72, 72 , 1)\n",
    "model.evaluate(test2, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is 0.8 and has decreased somewhat. And the accuracy is 0.74 and has raised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 A regression problem\n",
    "\n",
    "We want now to predict the images locations of the vertices of a triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, Y_train] = generate_dataset_regression(300, 20)\n",
    "visualize_prediction(X_train[0], Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_train[i] is composed of coordinates of the 3 vertices : U[0], V[0], U[1], V[1], U[2], V[2]\n",
    "\n",
    "So we build and train a regressor on this data.\n",
    "\n",
    "First, I try to use the Sklearn linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "Y_train_n=normalize(Y_train,norm='l1')\n",
    "\n",
    "regr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_test, Y_test] = generate_test_set_regression()\n",
    "\n",
    "Y_pred=regr.predict(X_test)\n",
    "visualize_prediction(X_test[2], Y_pred[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are pretty bad because the predict vertices don't match with the real ones.\n",
    "\n",
    "So now I try with a keras regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "def baseline_model_regression():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(16, (5, 5), activation='relu', input_shape=(72,72,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(6, activation='linear')) #here the linear regression activation\n",
    "    model.compile(loss='mean_squared_error',optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#Use the model\n",
    "regr = baseline_model_regression()\n",
    "#Y_train_n=normalize(Y_train)\n",
    "train2=X_train.reshape(X_train.shape[0], 72, 72 , 1)\n",
    "regr.fit(train2, Y_train_n,epochs =100,batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with 100 epochs, the accuracy remains low (around 45%) on the train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[X_test, Y_test] = generate_test_set_regression()\n",
    "\n",
    "test2=X_test.reshape(X_test.shape[0], 72, 72 , 1)\n",
    "Y_pred=regr.predict(test2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_prediction(X_test[2], Y_pred[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Image Denoising\n",
    "\n",
    "We modify some generating functions to generate pairs of images, with and without noise.\n",
    "We limit the noise for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_noise=(72*72)*np.random.random()\n",
    "\n",
    "def generate_a_drawing_noise(figsize, U, V, noise=random_noise):\n",
    "    fig = plt.figure(figsize=(figsize,figsize))\n",
    "    ax = plt.subplot(111)\n",
    "    plt.axis('Off')\n",
    "    ax.set_xlim(0,figsize)\n",
    "    ax.set_ylim(0,figsize)\n",
    "    ax.fill(U, V, \"k\")\n",
    "    fig.canvas.draw()\n",
    "    imdata = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)[::3].astype(np.float32)\n",
    "    imdata1 = imdata + noise * np.random.random(imdata.size)\n",
    "    \n",
    "    plt.close(fig)\n",
    "    return imdata,imdata1\n",
    "\n",
    "def generate_a_rectangle_noise(noise=random_noise, free_location=False):\n",
    "    figsize = 1.0    \n",
    "    U = np.zeros(4)\n",
    "    V = np.zeros(4)\n",
    "    if free_location:\n",
    "        corners = np.random.random(4)\n",
    "        top = max(corners[0], corners[1])\n",
    "        bottom = min(corners[0], corners[1])\n",
    "        left = min(corners[2], corners[3])\n",
    "        right = max(corners[2], corners[3])\n",
    "    else:\n",
    "        side = (0.3 + 0.7 * np.random.random()) * figsize\n",
    "        top = figsize/2 + side/2\n",
    "        bottom = figsize/2 - side/2\n",
    "        left = bottom\n",
    "        right = top\n",
    "    U[0] = U[1] = top\n",
    "    U[2] = U[3] = bottom\n",
    "    V[0] = V[3] = left\n",
    "    V[1] = V[2] = right\n",
    "    return generate_a_drawing_noise(figsize, U, V, noise)\n",
    "\n",
    "\n",
    "def generate_a_disk_noise(noise=random_noise, free_location=False):\n",
    "    figsize = 1.0\n",
    "    if free_location:\n",
    "        center = np.random.random(2)\n",
    "    else:\n",
    "        center = (figsize/2, figsize/2)\n",
    "    radius = (0.3 + 0.7 * np.random.random()) * figsize/2\n",
    "    N = 50\n",
    "    U = np.zeros(N)\n",
    "    V = np.zeros(N)\n",
    "    i = 0\n",
    "    for t in np.linspace(0, 2*np.pi, N):\n",
    "        U[i] = center[0] + np.cos(t) * radius\n",
    "        V[i] = center[1] + np.sin(t) * radius\n",
    "        i = i + 1\n",
    "    return generate_a_drawing_noise(figsize, U, V, noise)\n",
    "\n",
    "def generate_a_triangle_noise(noise=random_noise, free_location=False):\n",
    "    figsize = 1.0\n",
    "    if free_location:\n",
    "        U = np.random.random(3)\n",
    "        V = np.random.random(3)\n",
    "    else:\n",
    "        size = (0.3 + 0.7 * np.random.random())*figsize/2\n",
    "        middle = figsize/2\n",
    "        U = (middle, middle+size, middle-size)\n",
    "        V = (middle+size, middle-size, middle-size)\n",
    "    imdata1,imdata2 = generate_a_drawing_noise(figsize, U, V, noise)\n",
    "    return [imdata1,imdata2, [U[0], V[0], U[1], V[1], U[2], V[2]]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the pairs of image with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1,im2 = generate_a_rectangle_noise(random_noise, True)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im1.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im2.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1,im2 = generate_a_disk_noise(random_noise)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im1.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im2.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[im1,im2, v] = generate_a_triangle_noise(random_noise, False)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im1.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im2.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not succeed in building the hourglass network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_env]",
   "language": "python",
   "name": "conda-env-tensorflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
